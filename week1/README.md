# Week 1

The first topic to cover will be the introduction to RL and bandits.

## Chapter 1 of Sutton and Barto (optional reading)

Provides a very nice birds eye view of RL and will provide context to all the things that you will be reading about. That said, this is an optional reading.

## Chapter 2 of Sutton and Barto

It is based on multi-armed bandits. What are bandits? Well slot machines typically steal your money and so have been termed bandits in literature!
So... whats fascinating about slot machines? Well, imagine multiple bandits with different reward probabilities and a limited number of pulls -- how would you maximize the reward you can get?
The connections between this subject and RL will become more and more apparent as you study.

## Chapter 3 of Sutton and Barto (upto section 3.4)

These section will introduce you to Markov Decision Processes and their mathematical formulation. These will be a key element of our study of RL ahead.

## Lectures 6 and 8 from [CS747](https://www.cse.iitb.ac.in/~shivaram/teaching/cs747-a2022/index.html)

These lectures cover definitions for Policies, Value functions, Evaluation, as well as the optimality operator and will introduce you to a technique called value iteration used to find the optimal value function.
